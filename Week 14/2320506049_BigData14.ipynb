{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2a030e3",
      "metadata": {
        "id": "e2a030e3"
      },
      "source": [
        "# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099562db",
      "metadata": {
        "id": "099562db"
      },
      "source": [
        "## Objectives:\n",
        "- Understand and implement advanced machine learning tasks using Spark MLlib.\n",
        "- Build and evaluate models using real-world datasets.\n",
        "- Explore techniques like feature engineering and hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77df771a",
      "metadata": {
        "id": "77df771a"
      },
      "source": [
        "## Introduction to Spark MLlib\n",
        "Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4pWOSGkBOy7",
        "outputId": "d2714fce-2110-443e-d6a0-c54b05c7c2a4"
      },
      "id": "W4pWOSGkBOy7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ae225b",
      "metadata": {
        "id": "d9ae225b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0acf9ee-2c19-4bd6-e356-5492dfcfbb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b266267",
      "metadata": {
        "id": "0b266267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c1e5ae-b39f-42af-ad98-904d1ab84bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionExample\").getOrCreate()\n",
        "\n",
        "# Example dataset\n",
        "data = [\n",
        "    (1, Vectors.dense([2.0, 3.0]), 0),\n",
        "    (2, Vectors.dense([1.0, 5.0]), 1),\n",
        "    (3, Vectors.dense([2.5, 4.5]), 1),\n",
        "    (4, Vectors.dense([3.0, 6.0]), 0)\n",
        "]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n",
        "model = lr.fit(df)\n",
        "\n",
        "# Display coefficients and summary\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9066e04",
      "metadata": {
        "id": "b9066e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7685fc-9b8a-46d1-b48a-3cfda0bd22d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([12.5, 12.5]), array([3., 3.])]\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"KMeansClusteringExample\").getOrCreate()\n",
        "\n",
        "# Example dataset with DenseVector\n",
        "data = [\n",
        "    (1, Vectors.dense([1.0, 1.0])),\n",
        "    (2, Vectors.dense([5.0, 5.0])),\n",
        "    (3, Vectors.dense([10.0, 10.0])),\n",
        "    (4, Vectors.dense([15.0, 15.0]))\n",
        "]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='Features', k=2)\n",
        "model = kmeans.fit(df)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60a8d7e",
      "metadata": {
        "id": "a60a8d7e"
      },
      "source": [
        "## Homework\n",
        "- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n",
        "- Build a classification model using Spark MLlib and evaluate its performance.\n",
        "- Explore hyperparameter tuning using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Taxi Data ML\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "data = spark.read.csv(\"cleaned_taxi_data.csv\", header=True, inferSchema=True)\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNIqXavbB3Bl",
        "outputId": "adb79e86-24c0-4615-e33a-902d15459b33"
      },
      "id": "gNIqXavbB3Bl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+-----------+---------------+------------------+-------+-------------------+-------------------+--------------------+---------------------+-------------------+\n",
            "|    Trip_Distance_km|Time_of_Day|Day_of_Week|Passenger_Count|Traffic_Conditions|Weather|          Base_Fare|        Per_Km_Rate|     Per_Minute_Rate|Trip_Duration_Minutes|         Trip_Price|\n",
            "+--------------------+-----------+-----------+---------------+------------------+-------+-------------------+-------------------+--------------------+---------------------+-------------------+\n",
            "| 0.12498528560675952|          2|          0|            3.0|                 1|      0| 0.5183946488294316|                0.2|                0.55|   0.4250631368109379|0.09246378537997323|\n",
            "|   0.319989952210897|          0|          0|            1.0|                 0|      0|  0.505016722408027|0.08000000000000002|               0.825|   0.3096751719933815|  0.134843007561345|\n",
            "| 0.24596551786258417|          1|          1|            1.0|                 0|      0|0.23076923076923095|0.47333333333333333|               0.125|  0.28093703735957504|0.14352221678980742|\n",
            "| 0.16973139890685904|          1|          0|            3.0|                 0|      0| 0.3076923076923078|0.08666666666666667|                0.55|  0.15353130714969956|0.02912123686084067|\n",
            "|0.051029903902428335|          0|          1|            2.0|                 2|      0| 0.1806020066889633| 0.8066666666666666|                0.95|    0.734302882521989|0.16591934468745814|\n",
            "|0.017953687435225123|          0|          0|            4.0|                 0|      1| 0.5016722408026756| 0.7733333333333332|               0.475| 3.483410258643196...|0.01576353283563075|\n",
            "| 0.20163372042637445|          2|          0|            3.0|                 0|      0| 0.2541806020066891| 0.8533333333333333|  0.6000000000000001|   0.9171819211007577|  0.134843007561345|\n",
            "|  0.2378863585167329|          0|          0|            2.0|                 1|      1| 0.4615384615384618| 0.6799999999999999|  0.9249999999999998|   0.7848558739005487|0.21305683662932043|\n",
            "| 0.32648090074517067|          3|          0|            3.0|                 1|      0| 0.9264214046822744| 0.4799999999999999|                 1.0|   0.6525298267003397|  0.134843007561345|\n",
            "|  0.2799394187015486|          3|          1|            3.0|                 0|      0| 0.8662207357859532| 0.8466666666666667|0.025000000000000022|   0.7135765914830619|0.25161606535453357|\n",
            "| 0.05979958968809599|          1|          0|            2.0|                 0|      0|0.10367892976588633| 0.5066666666666666|  0.6000000000000001|   0.3196899764869807| 0.0701544099424399|\n",
            "| 0.06035201083994907|          3|          0|            4.0|                 0|      0| 0.7759197324414716|0.23333333333333334|               0.825|   0.2524601584951668|0.06539890162300202|\n",
            "| 0.10123117607707703|          2|          0|            4.0|                 1|      0| 0.8060200668896321| 0.8466666666666667|               0.275|   0.9572411390751545| 0.1552209083959451|\n",
            "| 0.17580803157724295|          0|          1|            4.0|                 1|      1| 0.7658862876254181| 0.7266666666666668|                0.25|   0.9245841679003746|0.19292654500910744|\n",
            "| 0.14445813120958062|          3|          2|            4.0|                 1|      0|0.11036789297658867|               0.98|  0.7749999999999999|   0.4578942784986502|0.19483470077648496|\n",
            "| 0.09681180686225238|          2|          2|            2.5|                 1|      0| 0.6421404682274249|0.15333333333333332| 0.04999999999999999|   0.4554123486893669| 0.0651313486676791|\n",
            "|  0.2052935105574011|          0|          1|            1.0|                 1|      1| 0.8327759197324415|0.22666666666666663|               0.375|   0.4529304188800836|0.11859254062009786|\n",
            "|  0.1222231798474941|          3|          0|            1.0|                 1|      0| 0.4581939799331104| 0.1866666666666667|  0.7250000000000001|  0.42697901245319164|0.10158942757861326|\n",
            "| 0.15260634319941355|          3|          2|            3.0|                 1|      1| 0.5284280936454849|0.06666666666666665|                0.35|   0.5380997997039101|0.08439301366344353|\n",
            "| 0.26391920529780927|          0|          0|            1.0|                 1|      0|  0.505016722408027| 0.4799999999999999|               0.625|  0.02246799616824871| 0.2380043087524803|\n",
            "+--------------------+-----------+-----------+---------------+------------------+-------+-------------------+-------------------+--------------------+---------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Membuat Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Taxi Data ML\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Memuat dataset\n",
        "data = spark.read.csv(\"cleaned_taxi_data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Mengubah kolom kategori menjadi numerik\n",
        "indexer = StringIndexer(inputCols=[\"Traffic_Conditions\", \"Weather\", \"Day_of_Week\"], outputCols=[\"Traffic_Idx\", \"Weather_Idx\", \"Day_Idx\"])\n",
        "data_indexed = indexer.fit(data).transform(data)\n",
        "\n",
        "# Memilih fitur dan label\n",
        "feature_cols = [\"Trip_Distance_km\", \"Time_of_Day\", \"Passenger_Count\", \"Traffic_Idx\", \"Weather_Idx\", \"Day_Idx\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "data_prepared = assembler.transform(data_indexed)\n",
        "\n",
        "# Menggunakan Trip_Price sebagai label (Anda perlu mengonversi ini menjadi kategori)\n",
        "data_final = data_prepared.withColumn(\"label\", (data_prepared.Trip_Price > 0.2).cast(\"integer\"))  # Contoh batasan\n",
        "\n",
        "# Memilih kolom yang relevan\n",
        "data_final = data_final.select(\"features\", \"label\")\n",
        "\n",
        "# Tampilkan data final\n",
        "data_final.show()\n",
        "\n",
        "# Membagi data menjadi training dan testing\n",
        "train_data, test_data = data_final.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Membuat model Logistic Regression\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Membuat parameter grid\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
        "    .addGrid(lr.maxIter, [10, 20]) \\\n",
        "    .build()\n",
        "\n",
        "# Cross-validation\n",
        "crossval = CrossValidator(estimator=lr,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"),\n",
        "                          numFolds=3)\n",
        "\n",
        "# Latih model dengan cross-validation\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Evaluasi model terbaik\n",
        "cv_predictions = cv_model.transform(test_data)\n",
        "cv_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\").evaluate(cv_predictions)\n",
        "\n",
        "print(f\"Akurasi setelah Cross-Validation: {cv_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkQtzd_zCoqh",
        "outputId": "4326f274-c33f-413c-8b1f-bb7290eb6980"
      },
      "id": "SkQtzd_zCoqh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[0.12498528560675...|    0|\n",
            "|[0.31998995221089...|    0|\n",
            "|[0.24596551786258...|    0|\n",
            "|[0.16973139890685...|    0|\n",
            "|[0.05102990390242...|    0|\n",
            "|[0.01795368743522...|    0|\n",
            "|[0.20163372042637...|    0|\n",
            "|[0.23788635851673...|    1|\n",
            "|[0.32648090074517...|    0|\n",
            "|[0.27993941870154...|    1|\n",
            "|[0.05979958968809...|    0|\n",
            "|[0.06035201083994...|    0|\n",
            "|[0.10123117607707...|    0|\n",
            "|[0.17580803157724...|    0|\n",
            "|[0.14445813120958...|    0|\n",
            "|[0.09681180686225...|    0|\n",
            "|[0.20529351055740...|    0|\n",
            "|[0.12222317984749...|    0|\n",
            "|[0.15260634319941...|    0|\n",
            "|(6,[0,2],[0.26391...|    1|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "Akurasi setelah Cross-Validation: 0.8071428571428572\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}