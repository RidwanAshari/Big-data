{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89f7684",
   "metadata": {},
   "source": [
    "# Hands-On Pertemuan 6: Data Processing dengan Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ce9d1",
   "metadata": {},
   "source": [
    "## Tujuan:\n",
    "- Memahami dan mempraktikkan data processing menggunakan Apache Spark.\n",
    "- Menggunakan Spark untuk operasi data yang efisien pada dataset besar.\n",
    "- Menerapkan teknik canggih dalam Spark untuk mengatasi kasus penggunaan nyata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c2f90",
   "metadata": {},
   "source": [
    "### 1. Pengenalan Spark DataFrames\n",
    "Spark DataFrame menyediakan struktur data yang optimal dengan operasi yang dioptimalkan untuk pemrosesan data besar, yang sangat mirip dengan DataFrame di Pandas atau di RDBMS.\n",
    "\n",
    "- **Tugas 1**: Buat DataFrame sederhana di Spark dan eksplorasi beberapa fungsi dasar yang tersedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986d01c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------+\n",
      "|EmployeeName|Department|  Salary|\n",
      "+------------+----------+--------+\n",
      "|        Iwan|   Manager|30000000|\n",
      "|      Fadzil|  Karyawan| 7000000|\n",
      "|       Restu|  Direktur|25000000|\n",
      "|         Rio|       CEO|52000000|\n",
      "+------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh membuat DataFrame sederhana dan operasi dasar\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('HandsOnPertemuan6').getOrCreate()\n",
    "\n",
    "data = [('Iwan', 'Manager', 30000000),\n",
    "        ('Fadzil', 'Karyawan', 7000000),\n",
    "        ('Restu', 'Direktur', 25000000),\n",
    "        ('Rio', 'CEO', 52000000)]\n",
    "columns = ['EmployeeName', 'Department', 'Salary']\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca66b73",
   "metadata": {},
   "source": [
    "### 2. Transformasi Dasar dengan DataFrames\n",
    "Pemrosesan data meliputi transformasi seperti filtering, selections, dan aggregations. Spark menyediakan cara efisien untuk melaksanakan operasi ini.\n",
    "\n",
    "- **Tugas 2**: Gunakan operasi filter, select, groupBy untuk mengekstrak informasi dari data, serta lakukan agregasi data untuk mendapatkan insight tentang dataset menggunakan perintah seperti mean, max, sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58232678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|EmployeeName|  Salary|\n",
      "+------------+--------+\n",
      "|        Iwan|30000000|\n",
      "|      Fadzil| 7000000|\n",
      "|       Restu|25000000|\n",
      "|         Rio|52000000|\n",
      "+------------+--------+\n",
      "\n",
      "+------------+----------+--------+\n",
      "|EmployeeName|Department|  Salary|\n",
      "+------------+----------+--------+\n",
      "|        Iwan|   Manager|30000000|\n",
      "|      Fadzil|  Karyawan| 7000000|\n",
      "|       Restu|  Direktur|25000000|\n",
      "|         Rio|       CEO|52000000|\n",
      "+------------+----------+--------+\n",
      "\n",
      "+----------+-----------+\n",
      "|Department|avg(Salary)|\n",
      "+----------+-----------+\n",
      "|   Manager|      3.0E7|\n",
      "|  Karyawan|  7000000.0|\n",
      "|  Direktur|      2.5E7|\n",
      "|       CEO|      5.2E7|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh operasi transformasi DataFrame\n",
    "df.select('EmployeeName', 'Salary').show()\n",
    "df.filter(df['Salary'] > 3000).show()\n",
    "df.groupBy('Department').avg('Salary').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89763d36",
   "metadata": {},
   "source": [
    "### 3. Bekerja dengan Tipe Data Kompleks\n",
    "Spark mendukung tipe data yang kompleks seperti maps, arrays, dan structs yang memungkinkan operasi yang lebih kompleks pada dataset yang kompleks.\n",
    "\n",
    "- **Tugas 3**: Eksplorasi bagaimana mengolah tipe data kompleks dalam Spark DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14701d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------+-----------+-----------------+\n",
      "|EmployeeName|Department|  Salary|SalaryBonus|TotalCompensation|\n",
      "+------------+----------+--------+-----------+-----------------+\n",
      "|        Iwan|   Manager|30000000|  3000000.0|            3.3E7|\n",
      "|      Fadzil|  Karyawan| 7000000|   700000.0|        7700000.0|\n",
      "|       Restu|  Direktur|25000000|  2500000.0|           2.75E7|\n",
      "|         Rio|       CEO|52000000|  5200000.0|           5.72E7|\n",
      "+------------+----------+--------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tambahkan kolom 'SalaryBonus'\n",
    "df_with_bonus = df.withColumn('SalaryBonus', df['Salary'] * 0.1)\n",
    "\n",
    "# Tambahkan kolom 'TotalCompensation' berdasarkan 'Salary' dan 'SalaryBonus'\n",
    "df_with_compensation = df_with_bonus.withColumn('TotalCompensation', df_with_bonus['Salary'] + df_with_bonus['SalaryBonus'])\n",
    "\n",
    "# Tampilkan hasil akhir\n",
    "df_with_compensation.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b58dd",
   "metadata": {},
   "source": [
    "### 4. Operasi Data Lanjutan\n",
    "Menggunakan Spark untuk operasi lanjutan seperti window functions, user-defined functions (UDFs), dan mengoptimalkan query.\n",
    "\n",
    "- **Tugas 4**: Implementasikan window function untuk menghitung running totals atau rangkings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "035312eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------+----+\n",
      "|EmployeeName|Department|  Salary|Rank|\n",
      "+------------+----------+--------+----+\n",
      "|         Rio|       CEO|52000000|   1|\n",
      "|       Restu|  Direktur|25000000|   1|\n",
      "|      Fadzil|  Karyawan| 7000000|   1|\n",
      "|        Iwan|   Manager|30000000|   1|\n",
      "+------------+----------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh menggunakan window functions\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "windowSpec = Window.partitionBy('Department').orderBy('Salary')\n",
    "df.withColumn('Rank', F.rank().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a097ec",
   "metadata": {},
   "source": [
    "### 5. Kesimpulan dan Eksplorasi Lebih Lanjut\n",
    "Review apa yang telah dipelajari tentang pemrosesan data menggunakan Spark dan eksplorasi teknik lebih lanjut untuk mengoptimalkan pemrosesan data Anda.\n",
    "- **Tugas 5**: Buat ringkasan dari semua operasi yang telah dilakukan dan bagaimana teknik ini dapat diterapkan pada proyek data Anda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ringkasan Operasi:\n",
    "Pembuatan DataFrame Dasar:\n",
    "Membuat DataFrame Spark dari daftar tuple.\n",
    "Ini termasuk data dasar seperti EmployeeName, Department, dan Salary.\n",
    "Transformasi Dasar:\n",
    "\n",
    "Seleksi dan Penyaringan:\n",
    "Memilih kolom tertentu dari DataFrame.\n",
    "Menyaring baris di mana Salary lebih besar dari nilai tertentu.\n",
    "\n",
    "Agregasi:\n",
    "Menggunakan groupBy untuk menghitung rata-rata gaji untuk setiap departemen.\n",
    "\n",
    "Tipe Data Kompleks:\n",
    "Operasi Kolom:\n",
    "Menambahkan kolom baru seperti SalaryBonus (10% dari Salary).\n",
    "Membuat kolom lain TotalCompensation, yang merupakan jumlah dari Salary dan SalaryBonus.\n",
    "\n",
    "Operasi Lanjutan:\n",
    "Window Functions:\n",
    "Menggunakan window functions untuk memberikan peringkat kepada karyawan berdasarkan gaji mereka di dalam departemen.\n",
    "Hal ini memungkinkan perhitungan peringkat, total berjalan, dan komputasi terpartisi.\n",
    "\n",
    "Bagaimana Teknik Ini Dapat Diterapkan pada Proyek Nyata:\n",
    "Transformasi Data:\n",
    "Kemampuan untuk mentransformasi data secara efisien (penyaringan, seleksi, dan penambahan kolom) sangat penting untuk pembersihan dan persiapan data dalam proyek seperti analisis keuangan atau segmentasi pelanggan.\n",
    "\n",
    "Agregasi dan Pengelompokan:\n",
    "Teknik agregasi (misalnya, groupBy, avg) sangat penting dalam menghasilkan wawasan dari dataset besar dalam analitik real-time atau sistem pelaporan.\n",
    "\n",
    "Penanganan Tipe Data Kompleks:\n",
    "Memanipulasi tipe data kompleks memungkinkan pemodelan data yang lebih rinci, seperti menangani data hierarkis atau bersarang dalam format seperti JSON, yang sering ditemukan dalam aliran data web atau IoT.\n",
    "\n",
    "Window Functions:\n",
    "Window functions sangat kuat dalam analisis deret waktu, untuk menghitung rata-rata bergerak, total berjalan, atau peringkat dalam dasbor intelijen bisnis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PraktikumBigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
